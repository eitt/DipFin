{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1hdwA46FmpoYGa0t_Asbglf2VF0gddkVJ","timestamp":1713559508166},{"file_id":"1nmlwJ5fSU8vOxXJAUiodVwg91bWEk0hj","timestamp":1712959672869},{"file_id":"1SZa3c_iroF8ge_r4mOiavLi4WPYjetAf","timestamp":1712951072578},{"file_id":"1hWqmAz0yXog6c-1DpulII38qk3Nrpepg","timestamp":1712349741951}],"authorship_tag":"ABX9TyN2ss5HEeKrd4fmPFLlgJqE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Diplomado en ciencia de datos para toma de decisiones financieras\n","\n","---\n","**Leonardo H. Talero-Sarmiento**\n","\n","ltalero@unab.edu.co\n","---\n","**Módulo 1: Fundamentos de Python y Estadística Básica Total Horas: 20 horas (5 sesiones) (Abril 5 a abril 19)**\n","---\n","* **Introducción a Python para Finanzas**: Configuración del entorno, sintaxis básica, estructuras de datos. (4 horas)\n","* **Programación en Python**: Funciones, bucles, manejo de errores. (4 horas)\n","* **Estadística Básica en Python**: Medidas de tendencia central y dispersión, probabilidad. (4 horas)\n","* **Adquisición y Selección de Datos Financieros**: Importación de datos (APIs, CSV), selección de variables relevantes. (4 horas)\n","* **Limpieza y Preparación de Datos**: Manejo de valores faltantes, transformación de variables. (4 horas)\n"],"metadata":{"id":"ZH7f0Bq27g74"}},{"cell_type":"markdown","source":["# Índice del Curso\n","\n","1. **Introducción a la Limpieza de Datos**\n","\n","- **Importancia de la Limpieza de Datos**: Explicación de cómo los datos sucios o mal gestionados pueden llevar a conclusiones erróneas en el análisis financiero.\n","- **Tipos de \"Suciedad\" en los Datos**: Identificación de problemas comunes como valores faltantes, datos atípicos, errores de entrada, y datos duplicados.\n","\n","2. **Manejo de Valores Faltantes**\n","\n","- **Identificación de Valores Faltantes**: Uso de Python para detectar la ausencia de datos en un conjunto de datos.\n","- **Técnicas de Manejo de Valores Faltantes**:\n","  - **Eliminación**: Cuando y cómo eliminar filas o columnas con valores faltantes.\n","  - **Imputación**: Técnicas para imputar datos faltantes utilizando la media, mediana, moda, o métodos más sofisticados como la imputación multivariante.\n","  - **Ejemplo práctico en Python**: Uso de `pandas` y `sklearn` para imputar valores faltantes.\n","\n","3. **Transformación de Variables**\n","\n","- **Escalar y Normalizar Datos**: Cómo y por qué normalizar y escalar datos en finanzas.\n","- **Transformación de Variables Categóricas**: Convertir variables categóricas en formatos útiles para modelización.\n","- **Reducción de Dimensionalidad**: Introducción a técnicas como PCA para reducir la cantidad de variables.\n","- **Ejercicio Práctico**: Los estudiantes deberán aplicar estas técnicas a un conjunto de datos financieros proporcionado, transformando todas las variables necesarias.\n","\n","4. **Integración y Almacenamiento de Datos Limpios**\n","- **Construcción de Pipelines de Datos**: Automatización del proceso de limpieza y transformación de datos usando `Pipeline` en `scikit-learn`.\n","- **Almacenamiento de Datos Transformados**: Mejores prácticas para el almacenamiento de conjuntos de datos limpios y transformados.\n","\n","\n","\n"],"metadata":{"id":"FM2Lj_OV7FDX"}},{"cell_type":"markdown","source":["# 1. Introducción a la Limpieza de Datos\n","\n","En el mundo de las finanzas, la calidad de los datos puede ser tan crítica como las decisiones que de ellos derivan. Un análisis financiero preciso, ya sea para evaluación de inversiones, gestión de riesgos, o planificación estratégica, depende en gran medida de la calidad de los datos utilizados. Este documento explora la importancia de la limpieza de datos, los problemas comunes que se deben abordar, y proporciona un ejemplo introductorio de cómo identificar datos faltantes usando Python y pandas.\n","\n","## 1. **Importancia de la Limpieza de Datos**\n","\n","La limpieza de datos es el proceso de detectar y corregir (o eliminar) registros corruptos o inexactos de un conjunto de datos. En el contexto de las finanzas:\n","\n","- **Decisiones informadas**: Los datos precisos y bien gestionados aseguran que las decisiones financieras se basen en la información más fiable y actualizada.\n","- **Eficiencia analítica**: Datos limpios reducen significativamente el riesgo de errores en el análisis y ayudan a mejorar la eficiencia operativa al automatizar procesos.\n","- **Cumplimiento y transparencia**: Mantener la integridad de los datos es crucial para cumplir con regulaciones financieras y mantener la transparencia ante los stakeholders.\n","\n","## 2. **Problemas Comunes en los Datos**\n","\n","Los conjuntos de datos, especialmente los grandes, a menudo presentan varios problemas que pueden distorsionar los resultados del análisis si no se manejan adecuadamente:\n","\n","- **Valores faltantes**: Los registros incompletos pueden surgir por diversos motivos, desde errores en la entrada de datos hasta fallos en la transmisión o almacenamiento de datos.\n","- **Errores de entrada**: Equivocaciones o descuidos al ingresar datos, que pueden introducir errores significativos en los análisis financieros.\n","- **Datos duplicados**: La presencia de registros repetidos puede llevar a una interpretación errónea del volumen de actividad o de la magnitud de un parámetro financiero.\n","- **Datos atípicos (Outliers)**: Valores que se desvían significativamente del resto de datos y que pueden indicar un error o una condición de mercado anómala.\n","\n","## 3. **Ejemplo Introductorio en Python**\n","\n","Para empezar a abordar estos problemas, uno de los primeros pasos en la limpieza de datos es identificar valores faltantes. A continuación, se muestra cómo utilizar `pandas` para este propósito:\n","\n","```python\n","import pandas as pd\n","\n","# Supongamos que tenemos un DataFrame llamado 'data'\n","data = pd.DataFrame({\n","    'precio': [100, 101, 102, None, 104],\n","    'volumen': [200, None, 150, 140, 130]\n","})\n","\n","# Mostrar datos faltantes\n","print(data.isnull())\n","\n","# Resultado de los datos faltantes\n","print(\"\\nDatos Faltantes por Columna:\")\n","print(data.isnull().sum())\n","```\n","\n","Este código inicialmente carga datos en un DataFrame y luego utiliza la función `isnull()` para identificar y sumar todos los valores faltantes por columna. Este es un primer paso esencial para entender el alcance de los problemas en el conjunto de datos y planificar los pasos siguientes para la limpieza.\n","\n"],"metadata":{"id":"9ursZ4lCG_qm"}},{"cell_type":"code","source":["import pandas as pd\n","# Supongamos que tenemos un DataFrame llamado 'data'\n","data = pd.DataFrame({\n","    'precio': [100, 101, 102, None, 104],\n","    'volumen': [200, None, 150, 140, 130]\n","})\n","# Mostrar datos faltantes\n","print(data.isnull())\n","\n","# Resultado de los datos faltantes\n","print(\"\\nDatos Faltantes por Columna:\")\n","print(data.isnull().sum())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ch-5ftVMJIye","executionInfo":{"status":"ok","timestamp":1713560149420,"user_tz":300,"elapsed":288,"user":{"displayName":"LEONARDO HERNAN TALERO SARMIENTO","userId":"18356281857447711093"}},"outputId":"f57f7e5d-5ceb-4270-ff73-f167ea6727fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["   precio  volumen\n","0   False    False\n","1   False     True\n","2   False    False\n","3    True    False\n","4   False    False\n","\n","Datos Faltantes por Columna:\n","precio     1\n","volumen    1\n","dtype: int64\n"]}]},{"cell_type":"markdown","source":["## 3. Haciendo uso de datos reales\n","\n","Por favor descargue los datos de ejemplo de [kaggle](https://www.kaggle.com/datasets/yaminh/applicant-details-for-loan-approve/code)\n","\n","| Variable Name (English) | Description (English) | Description (Spanish) |\n","|---|---|---|\n","| Applicant_ID | Unique identifier for each loan applicant. | Identificador único para cada solicitante de préstamo. |\n","| Annual_Income | Annual income of the loan applicant. | Ingreso anual del solicitante del préstamo. |\n","| Applicant_Age | Age of the loan applicant. | Edad del solicitante del préstamo. |\n","| Work_Experience | Number of years of work experience of the loan applicant. | Número de años de experiencia laboral del solicitante del préstamo. |\n","| Marital_Status | Marital status of the loan applicant. | Estado civil del solicitante del préstamo. |\n","| House_Ownership | Ownership status of the applicant's residence. | Estado de propiedad de la residencia del solicitante. |\n","| Vehicle_Ownership (car) | Ownership status of the applicant's vehicle. | Estado de propiedad del vehículo del solicitante (carro). |\n","| Occupation | Profession or occupation of the loan applicant. | Profesión u ocupación del solicitante del préstamo. |\n","| Residence_City | City where the loan applicant resides. | Ciudad donde reside el solicitante del préstamo. |\n","| Residence_State | State where the loan applicant resides. | Estado donde reside el solicitante del préstamo. |\n","| Years_in_Current_Employment | Number of years the applicant has been in their current job. | Número de años que el solicitante lleva en su trabajo actual. |\n","| Years_in_Current_Residence | Number of years the applicant has been residing in their current residence. | Número de años que el solicitante lleva residiendo en su domicilio actual. |\n","| Loan_Default_Risk | Indicator of loan default risk, with values indicating whether the loan applicant is at risk of defaulting on the loan. | Indicador de riesgo de impago del préstamo, con valores que indican si el solicitante del préstamo corre el riesgo de no pagar. |\n"],"metadata":{"id":"847vP6l4KH6H"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","df = pd.read_csv(\"/content/Applicant-details.csv\")\n","\n","# Resultado de los datos faltantes\n","print(\"\\nDatos Faltantes por Columna:\")\n","print(df.isnull().sum())\n","\n","# Generar máscara aleatoria por columna\n","porcentaje_perdido = 0.05  # Ajustar el porcentaje de valores perdidos deseado\n","\n","def generar_mascara_columna(columna):\n","    # Generar máscara aleatoria con probabilidad especificada\n","    mascara_columna = np.random.choice([True, False], size=len(columna), p=[porcentaje_perdido, 1-porcentaje_perdido])\n","    # Convertir valores a NaN según la máscara\n","    columna.loc[mascara_columna] = np.nan\n","    return columna\n","\n","# Aplicar la función a cada columna\n","df = df.apply(generar_mascara_columna, axis=0)\n","\n","\n","# Resultado de los datos faltantes\n","print(\"\\nDatos Faltantes por Columna:\")\n","print(df.isnull().sum())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"turjMttVKsru","executionInfo":{"status":"ok","timestamp":1713560924680,"user_tz":300,"elapsed":383,"user":{"displayName":"LEONARDO HERNAN TALERO SARMIENTO","userId":"18356281857447711093"}},"outputId":"963bc995-ef24-43ac-d607-f5c71d54f6f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Datos Faltantes por Columna:\n","Applicant_ID                   0\n","Annual_Income                  0\n","Applicant_Age                  0\n","Work_Experience                0\n","Marital_Status                 0\n","House_Ownership                0\n","Vehicle_Ownership(car)         0\n","Occupation                     0\n","Residence_City                 0\n","Residence_State                0\n","Years_in_Current_Employment    0\n","Years_in_Current_Residence     0\n","Loan_Default_Risk              0\n","dtype: int64\n","\n","Datos Faltantes por Columna:\n","Applicant_ID                   4936\n","Annual_Income                  5096\n","Applicant_Age                  5077\n","Work_Experience                4897\n","Marital_Status                 4960\n","House_Ownership                5054\n","Vehicle_Ownership(car)         5056\n","Occupation                     5001\n","Residence_City                 4979\n","Residence_State                5018\n","Years_in_Current_Employment    4927\n","Years_in_Current_Residence     4980\n","Loan_Default_Risk              5138\n","dtype: int64\n"]}]},{"cell_type":"markdown","source":["# 2. Manejo de Valores Faltantes"],"metadata":{"id":"fLxVHr5THv1J"}},{"cell_type":"markdown","source":["## Manejo de Valores Faltantes\n","\n","El manejo adecuado de valores faltantes en conjuntos de datos es crucial para el análisis de datos financiero confiable y preciso. Los datos incompletos pueden llevar a conclusiones erróneas y afectar el rendimiento de los modelos de predicción. A continuación, exploraremos diversas técnicas para tratar con valores faltantes, proporcionaremos ejemplos prácticos en Python y propondremos un ejercicio para aplicar estos conocimientos.\n","\n","### 1. **Técnicas para Manejar Valores Faltantes**\n","\n","Los valores faltantes pueden ser abordados de varias maneras, dependiendo de la naturaleza del problema y la cantidad de datos faltantes. Algunas de las técnicas más comunes incluyen:\n","\n","- **Eliminación**: Consiste en eliminar filas o columnas que contienen valores faltantes. Esta técnica es simple pero puede resultar en la pérdida de información importante si los datos faltantes son extensos.\n","- **Imputación**:\n","  - **Media/Mediana/Moda**: Sustituir los valores faltantes por la media, mediana o moda es efectivo para características numéricas o categóricas respectivamente.\n","  - **Interpolación**: Método útil especialmente en series temporales, donde los valores faltantes pueden ser estimados a partir de valores adyacentes.\n","  \n","### 2. **Ejemplo Práctico en Python**\n","\n","Para ilustrar cómo manejar valores faltantes en un conjunto de datos financieros, utilizaremos Python con `pandas` para la eliminación y `SimpleImputer` de `sklearn` para la imputación.\n","\n","#### Eliminación de Filas con Valores Faltantes:\n","\n","```python\n","import pandas as pd\n","\n","# Cargar un ejemplo de datos financieros\n","data = pd.DataFrame({\n","    'precio': [100, 101, None, 103, 104],\n","    'volumen': [200, None, 150, 140, 130]\n","})\n","\n","# Eliminar filas con cualquier valor faltante\n","clean_data = data.dropna()\n","print(clean_data)\n","```\n","\n"],"metadata":{"id":"s6k4u5RpM9_v"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Cargar un ejemplo de datos financieros\n","data = pd.DataFrame({\n","    'precio': [100, 101, None, 103, 104],\n","    'volumen': [200, None, 150, 140, 130]\n","})\n","\n","# Eliminar filas con cualquier valor faltante\n","clean_data = data.dropna()\n","print(clean_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ctTgM2uZOWaY","executionInfo":{"status":"ok","timestamp":1713561496718,"user_tz":300,"elapsed":15,"user":{"displayName":"LEONARDO HERNAN TALERO SARMIENTO","userId":"18356281857447711093"}},"outputId":"b1ca393a-4170-4b26-d127-df7bf1fa5bb4"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["   precio  volumen\n","0   100.0    200.0\n","3   103.0    140.0\n","4   104.0    130.0\n"]}]},{"cell_type":"markdown","source":["#### Imputación de Valores Faltantes:\n","\n","```python\n","from sklearn.impute import SimpleImputer\n","import numpy as np\n","\n","# Imputador para sustituir valores faltantes con la media de la columna\n","imputer = SimpleImputer(strategy='mean')\n","\n","# Aplicar imputación\n","data['precio'] = imputer.fit_transform(data[['precio']])\n","\n","# Comprobar el resultado\n","print(data)\n","```\n","\n"],"metadata":{"id":"r40vdG_dOOFQ"}},{"cell_type":"code","source":["from sklearn.impute import SimpleImputer\n","import numpy as np\n","\n","# Imputador para sustituir valores faltantes con la media de la columna\n","imputer = SimpleImputer(strategy='mean')\n","\n","# Aplicar imputación\n","data['precio'] = imputer.fit_transform(data[['precio']])\n","\n","# Comprobar el resultado\n","print(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ols6buX-OYcV","executionInfo":{"status":"ok","timestamp":1713561506867,"user_tz":300,"elapsed":1954,"user":{"displayName":"LEONARDO HERNAN TALERO SARMIENTO","userId":"18356281857447711093"}},"outputId":"056f939c-21a5-4d53-fde5-d1469df155dd"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["   precio  volumen\n","0   100.0    200.0\n","1   101.0      NaN\n","2   102.0    150.0\n","3   103.0    140.0\n","4   104.0    130.0\n"]}]},{"cell_type":"markdown","source":["### 3. **Ejercicio Práctico**\n","\n","**Objetivo del ejercicio**: Limpiar un conjunto de datos de mercado bursátil, enfocándose en el manejo de valores faltantes.\n","\n","**Datos proporcionados**: Un archivo CSV que contiene precios diarios de acciones con algunas entradas faltantes en precios y volúmenes.\n","\n","**Tareas**:\n","1. Cargar el conjunto de datos desde un archivo CSV.\n","2. Identificar y contar los valores faltantes en cada columna.\n","3. Aplicar imputación para rellenar los valores faltantes utilizando la mediana para los precios y la media para los volúmenes.\n","4. Guardar el conjunto de datos limpio en un nuevo archivo CSV.\n","\n","#### Código de Ejercicio Sugerido:\n","\n","```python\n","# Carga de datos\n","data = pd.read_csv('datos_mercado_bursatil.csv')\n","\n","# Visualización de valores faltantes\n","print(data.isnull().sum())\n","\n","# Configurar imputadores\n","precio_imputer = SimpleImputer(strategy='median')\n","volumen_imputer = SimpleImputer(strategy='mean')\n","\n","# Aplicar imputación\n","data['precio'] = precio_imputer.fit_transform(data[['precio']])\n","data['volumen'] = volumen_imputer.fit_transform(data[['volumen']])\n","\n","# Guardar los datos limpios\n","data.to_csv('datos_mercado_bursatil_limpio.csv', index=False)\n","\n","# Mostrar los datos finales\n","print(data.head())\n","```\n"],"metadata":{"id":"e5j5G3M2ORi3"}},{"cell_type":"markdown","source":["Para ampliar el ejemplo práctico de manejo de valores faltantes en un conjunto de datos financieros, podemos añadir una columna con variables de tipo `str` (cadena de caracteres). Esto nos permitirá demostrar cómo abordar los valores faltantes en datos categóricos.\n","\n","### Modificación del Conjunto de Datos\n","\n","Vamos a agregar una columna llamada `categoria`, que podría representar, por ejemplo, la clasificación de riesgo de las acciones o cualquier otro dato categórico relevante en el contexto financiero.\n","\n","### Ejemplo Práctico en Python\n","\n","A continuación, modificaremos el código para incluir esta nueva columna y aplicaremos técnicas de imputación tanto a los datos numéricos como a los categóricos:\n","\n","```python\n","import pandas as pd\n","from sklearn.impute import SimpleImputer\n","\n","# Crear un DataFrame con una nueva columna de tipo str\n","data = pd.DataFrame({\n","    'precio': [100, 101, None, 103, 104],\n","    'volumen': [200, None, 150, 140, 130],\n","    'categoria': ['Alto', 'Medio', None, 'Alto', 'Bajo']\n","})\n","\n","# Mostrar datos originales\n","print(\"Datos originales:\")\n","print(data)\n","\n","# Imputación para datos numéricos\n","num_imputer = SimpleImputer(strategy='mean')\n","data['precio'] = num_imputer.fit_transform(data[['precio']])\n","data['volumen'] = num_imputer.fit_transform(data[['volumen']])\n","\n","# Imputación para datos categóricos\n","cat_imputer = SimpleImputer(strategy='most_frequent')\n","data['categoria'] = cat_imputer.fit_transform(data[['categoria']])\n","\n","# Mostrar datos después de la imputación\n","print(\"\\nDatos después de la imputación:\")\n","print(data)\n","```\n","\n","### Explicación del Código\n","\n","1. **Creación del DataFrame**: Se define un DataFrame de `pandas` con una nueva columna llamada `categoria`, que incluye valores categóricos, algunos de los cuales son `None` (similares a los valores faltantes en pandas).\n","\n","2. **Imputación para Datos Numéricos**:\n","    - Se utiliza `SimpleImputer` con la estrategia `mean` para imputar los valores faltantes en las columnas numéricas (`precio` y `volumen`).\n","\n","3. **Imputación para Datos Categóricos**:\n","    - Se emplea `SimpleImputer` con la estrategia `most_frequent` para rellenar los valores faltantes en la columna categórica (`categoria`). Esta estrategia reemplaza los valores faltantes por el valor más frecuente en la columna, lo cual es comúnmente utilizado para datos categóricos.\n","\n"],"metadata":{"id":"arYEJuMTOhgT"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.impute import SimpleImputer\n","\n","# Crear un DataFrame con una nueva columna de tipo str\n","data = pd.DataFrame({\n","    'precio': [100, 101, None, 103, 104],\n","    'volumen': [200, None, 150, 140, 130],\n","    'categoria': ['Alto', 'Medio', None, 'Alto', 'Bajo']\n","})\n","\n","# Mostrar datos originales\n","print(\"Datos originales:\")\n","print(data)\n","\n","# Imputación para datos numéricos\n","num_imputer = SimpleImputer(strategy='mean')\n","data['precio'] = num_imputer.fit_transform(data[['precio']])\n","data['volumen'] = num_imputer.fit_transform(data[['volumen']])\n","\n","# Imputación para datos categóricos\n","mode_categoria = data['categoria'].mode().iloc[0]  # Find the most frequent category\n","data['categoria'].fillna(mode_categoria, inplace=True)\n","\n","\n","# Mostrar datos después de la imputación\n","print(\"\\nDatos después de la imputación:\")\n","print(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jPMHyapCOo37","executionInfo":{"status":"ok","timestamp":1713561728811,"user_tz":300,"elapsed":244,"user":{"displayName":"LEONARDO HERNAN TALERO SARMIENTO","userId":"18356281857447711093"}},"outputId":"9d0e4487-27e9-49f8-c014-e583b2dca16f"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Datos originales:\n","   precio  volumen categoria\n","0   100.0    200.0      Alto\n","1   101.0      NaN     Medio\n","2     NaN    150.0      None\n","3   103.0    140.0      Alto\n","4   104.0    130.0      Bajo\n","\n","Datos después de la imputación:\n","   precio  volumen categoria\n","0   100.0    200.0      Alto\n","1   101.0    155.0     Medio\n","2   102.0    150.0      Alto\n","3   103.0    140.0      Alto\n","4   104.0    130.0      Bajo\n"]}]},{"cell_type":"markdown","source":["Cuando trabajamos con series de tiempo en finanzas, es común encontrar valores faltantes que pueden distorsionar los análisis si no se tratan adecuadamente. Una técnica útil para manejar valores faltantes en series de tiempo es la interpolación, que estima los valores faltantes basándose en otros valores conocidos de la serie temporal.\n","\n","### Ejemplo Práctico en Python: Interpolación en Series de Tiempo\n","\n","En este ejemplo, crearemos un conjunto de datos de serie temporal con algunos valores faltantes y utilizaremos interpolación para llenar esos huecos. Vamos a utilizar `pandas`, que ofrece varias opciones para interpolación.\n","\n","#### Creación del Conjunto de Datos\n","\n","Supongamos que tenemos datos diarios de precios de acciones, pero algunos días faltan debido a errores en la captura de datos o días no comerciales.\n","\n","```python\n","import pandas as pd\n","import numpy as np\n","\n","# Crear fechas de índice\n","idx = pd.date_range('2021-01-01', periods=10, freq='D')\n","\n","# Crear datos con valores faltantes\n","data = pd.Series([100, 101, np.nan, 103, np.nan, 105, 106, np.nan, 108, 109], index=idx)\n","\n","# Mostrar la serie con valores faltantes\n","print(\"Serie original con valores faltantes:\")\n","print(data)\n","```\n","\n","#### Aplicando Interpolación\n","\n","Utilizaremos la función `interpolate()` de `pandas`, que por defecto utiliza una interpolación lineal para estimar los valores faltantes.\n","\n","```python\n","# Aplicar interpolación\n","interpolated_data = data.interpolate()\n","\n","# Mostrar la serie después de la interpolación\n","print(\"\\nSerie después de la interpolación:\")\n","print(interpolated_data)\n","```\n","\n","### Código Completo\n","\n","Aquí está el código completo con la creación de datos y la interpolación aplicada:\n","\n","```python\n","import pandas as pd\n","import numpy as np\n","\n","# Crear fechas de índice\n","idx = pd.date_range('2021-01-01', periods=10, freq='D')\n","\n","# Crear datos con valores faltantes\n","data = pd.Series([100, 101, np.nan, 103, np.nan, 105, 106, np.nan, 108, 109], index=idx)\n","\n","# Mostrar la serie con valores faltantes\n","print(\"Serie original con valores faltantes:\")\n","print(data)\n","\n","# Aplicar interpolación\n","interpolated_data = data.interpolate()\n","\n","# Mostrar la serie después de la interpolación\n","print(\"\\nSerie después de la interpolación:\")\n","print(interpolated_data)\n","```\n","\n","### Explicación del Método de Interpolación\n","\n","- **Interpolación Lineal**: Este método estima los valores faltantes realizando una interpolación lineal, lo que significa que asume una tasa de cambio constante entre los puntos conocidos antes y después de los valores faltantes. Es especialmente útil en datos que cambian gradualmente y es común en el análisis financiero donde los precios de las acciones no suelen saltar abruptamente bajo condiciones normales de mercado.\n","\n","Este enfoque no solo es eficaz para completar datos faltantes en series de tiempo sino que también mantiene la coherencia temporal de los datos, lo cual es crucial para cualquier análisis técnico o modelos predictivos en finanzas."],"metadata":{"id":"eg7yLERYQOpO"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# Crear fechas de índice\n","idx = pd.date_range('2021-01-01', periods=10, freq='D')\n","\n","# Crear datos con valores faltantes\n","data = pd.Series([100, 101, np.nan, 103, np.nan, 105, 106, np.nan, 108, 109], index=idx)\n","\n","# Mostrar la serie con valores faltantes\n","print(\"Serie original con valores faltantes:\")\n","print(data)\n","\n","# Aplicar interpolación\n","interpolated_data = data.interpolate()\n","\n","# Mostrar la serie después de la interpolación\n","print(\"\\nSerie después de la interpolación:\")\n","print(interpolated_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZjwGP_JzQTOY","executionInfo":{"status":"ok","timestamp":1713562045202,"user_tz":300,"elapsed":2,"user":{"displayName":"LEONARDO HERNAN TALERO SARMIENTO","userId":"18356281857447711093"}},"outputId":"9d28ab06-9d4b-406b-a71c-dd6b56b90f07"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Serie original con valores faltantes:\n","2021-01-01    100.0\n","2021-01-02    101.0\n","2021-01-03      NaN\n","2021-01-04    103.0\n","2021-01-05      NaN\n","2021-01-06    105.0\n","2021-01-07    106.0\n","2021-01-08      NaN\n","2021-01-09    108.0\n","2021-01-10    109.0\n","Freq: D, dtype: float64\n","\n","Serie después de la interpolación:\n","2021-01-01    100.0\n","2021-01-02    101.0\n","2021-01-03    102.0\n","2021-01-04    103.0\n","2021-01-05    104.0\n","2021-01-06    105.0\n","2021-01-07    106.0\n","2021-01-08    107.0\n","2021-01-09    108.0\n","2021-01-10    109.0\n","Freq: D, dtype: float64\n"]}]},{"cell_type":"markdown","source":["#3. Transformación de Variables\n","\n","En el análisis financiero, preparar correctamente los datos es crucial para el desarrollo de modelos predictivos robustos y precisos. La transformación de variables es una etapa fundamental en la preparación de datos, que implica ajustar las características del conjunto de datos para mejorar la calidad y la eficacia del análisis.\n","\n","## 1. **Escalar y Normalizar Datos**\n","\n","La normalización y el escalado de datos son técnicas esenciales para estandarizar el rango de las variables independientes o características de los datos. En finanzas:\n","\n","- **Importancia del Escalado**: Diferentes variables financieras pueden tener diferentes unidades de medida (como dólares, porcentajes, o puntos base). Escalar esos datos a un rango común es crucial para evitar que las variables con mayor magnitud dominen el modelo.\n","- **Impacto en Modelos Predictivos**: Muchos algoritmos de aprendizaje automático, como los basados en distancias (k-NN, SVM) o gradientes (regresión logística, redes neuronales), asumen que todas las características están en la misma escala, lo que hace que el escalado sea esencial para un rendimiento óptimo del modelo.\n","\n","## 2. **Transformación de Variables Categóricas y Reducción de Dimensionalidad**\n","\n","- **Manejo de Variables Categóricas**: Las variables categóricas deben ser transformadas en formatos que los modelos predictivos puedan entender. Una técnica común es el *one-hot encoding*, que convierte variables categóricas en una serie de variables binarias.\n","  \n","- **Reducción de Dimensionalidad**: Técnicas como el Análisis de Componentes Principales (PCA) son usadas para reducir el número de variables, manteniendo la mayor cantidad de información posible. Esto es útil en conjuntos de datos financieros grandes para simplificar los modelos y reducir el riesgo de sobreajuste.\n","\n","## 3. **Ejemplo y Ejercicio Práctico en Python**\n","\n","**Ejemplo Práctico**:\n","Aquí mostramos cómo utilizar `MinMaxScaler`, `PCA`, y `pd.get_dummies()` en Python para preparar un conjunto de datos para análisis predictivo.\n","\n","```python\n","import pandas as pd\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import OneHotEncoder\n","\n","# Ejemplo de datos\n","data = pd.DataFrame({\n","    'precio': [100, 200, 300, 400, 500],\n","    'categoria': ['A', 'B', 'A', 'B', 'C']\n","})\n","\n","# Normalización de la columna 'precio'\n","scaler = MinMaxScaler()\n","data['precio_norm'] = scaler.fit_transform(data[['precio']])\n","\n","# Transformación de variables categóricas\n","data_encoded = pd.get_dummies(data, columns=['categoria'])\n","\n","# Aplicación de PCA\n","pca = PCA(n_components=1)\n","data_encoded['PCA1'] = pca.fit_transform(data_encoded.drop(['precio', 'precio_norm'], axis=1))\n","\n","# Mostrar datos transformados\n","print(data_encoded)\n","```\n","\n","**Ejercicio Práctico**:\n","- **Objetivo**: Aplicar técnicas de escalado, codificación y reducción de dimensionalidad a un conjunto de datos de bonos o acciones.\n","- **Datos**: Un archivo CSV que contiene precios, volumen y clasificaciones sectoriales de acciones.\n","- **Tareas**:\n","  1. Cargar el conjunto de datos.\n","  2. Escalar los precios y volumen usando `MinMaxScaler`.\n","  3. Aplicar one-hot encoding a las clasificaciones sectoriales.\n","  4. Reducir la dimensionalidad con PCA.\n","  5. Guardar el conjunto de datos transformado para análisis futuros.\n","\n"],"metadata":{"id":"nBBYDThpHxIJ"}},{"cell_type":"markdown","source":["# 4. Integración y Almacenamiento de Datos Limpios\n","\n","## Integración y Almacenamiento de Datos Limpio\n","\n","La gestión eficaz de los datos requiere no solo técnicas de limpieza y transformación adecuadas, sino también la capacidad de integrar estas tareas en un flujo de trabajo automatizado y almacenar los resultados de manera eficiente. Esto es crucial en el análisis financiero, donde la precisión y la accesibilidad de los datos son fundamentales.\n","\n","### 1. **Construcción de Pipelines de Datos**\n","\n","Los pipelines de datos son herramientas esenciales en `scikit-learn` que ayudan a automatizar y secuenciar procesos de transformación y limpieza de datos, asegurando que se apliquen de manera consistente y eficiente.\n","\n","- **Automatización y Consistencia**: Los pipelines garantizan que las mismas operaciones de procesamiento de datos se apliquen en el mismo orden, reduciendo errores humanos y aumentando la eficiencia.\n","- **Facilidad de Pruebas**: Facilitan la experimentación con diferentes estrategias de procesamiento y parámetros.\n","- **Preparación para el Modelado**: Preparan los datos de manera que se puedan alimentar directamente a modelos de machine learning para entrenamiento y validación.\n","\n","### 2. **Almacenamiento de Datos**\n","\n","Una vez que los datos están limpios y transformados, es crucial almacenarlos de manera que sean fácilmente accesibles y seguros.\n","\n","- **Formatos de Archivo**: Los datos pueden ser almacenados en formatos como CSV, JSON, o parquet. El formato CSV es ampliamente usado por su simplicidad, aunque parquet es preferido en entornos de big data por su eficiencia en espacio y velocidad de lectura.\n","- **Bases de Datos**: Las bases de datos relacionales (como PostgreSQL, MySQL) o no relacionales (como MongoDB) son opciones robustas para el almacenamiento de datos, especialmente cuando se manejan grandes volúmenes o se requiere acceso concurrente.\n","- **Mejores Prácticas**: Incluir prácticas como la copia de seguridad regular, la utilización de índices para acelerar las consultas y mantener la seguridad de los datos para proteger la información sensible.\n","\n","### 3. **Ejemplo Práctico en Python**\n","\n","Vamos a crear un pipeline en `scikit-learn` que incluya imputación, escalado y PCA, y luego almacenaremos el resultado en un formato CSV.\n","\n","```python\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","from sklearn.datasets import load_iris\n","import pandas as pd\n","\n","# Cargar ejemplo de datos\n","data = load_iris()\n","df = pd.DataFrame(data.data, columns=data.feature_names)\n","\n","# Crear el pipeline\n","pipeline = Pipeline([\n","    ('imputer', SimpleImputer(strategy='mean')),  # Paso de imputación\n","    ('scaler', StandardScaler()),                # Paso de escalado\n","    ('pca', PCA(n_components=2))                 # Reducción de dimensionalidad\n","])\n","\n","# Ejecutar el pipeline\n","transformed_data = pipeline.fit_transform(df)\n","\n","# Convertir a DataFrame\n","transformed_df = pd.DataFrame(transformed_data, columns=['Component 1', 'Component 2'])\n","\n","# Almacenar en CSV\n","transformed_df.to_csv('transformed_data.csv', index=False)\n","\n","print(\"Datos transformados almacenados con éxito.\")\n","```\n"],"metadata":{"id":"OOGh-k-mHyN6"}},{"cell_type":"code","source":["from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","from sklearn.datasets import load_iris\n","import pandas as pd\n","\n","# Cargar ejemplo de datos\n","data = load_iris()\n","df = pd.DataFrame(data.data, columns=data.feature_names)\n","print(df.head())\n","# Crear el pipeline\n","pipeline = Pipeline([\n","    ('imputer', SimpleImputer(strategy='mean')),  # Paso de imputación\n","    ('scaler', StandardScaler()),                # Paso de escalado\n","    ('pca', PCA(n_components=2))                 # Reducción de dimensionalidad\n","])\n","\n","# Ejecutar el pipeline\n","transformed_data = pipeline.fit_transform(df)\n","\n","# Convertir a DataFrame\n","transformed_df = pd.DataFrame(transformed_data, columns=['Component 1', 'Component 2'])\n","print(transformed_df)\n","# Almacenar en CSV\n","transformed_df.to_csv('transformed_data.csv', index=False)\n","\n","print(\"Datos transformados almacenados con éxito.\")"],"metadata":{"id":"otkGBXXaHvKW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713562516220,"user_tz":300,"elapsed":235,"user":{"displayName":"LEONARDO HERNAN TALERO SARMIENTO","userId":"18356281857447711093"}},"outputId":"a1cb609b-36a7-4a2e-a623-6fc544561c2f"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n","0                5.1               3.5                1.4               0.2\n","1                4.9               3.0                1.4               0.2\n","2                4.7               3.2                1.3               0.2\n","3                4.6               3.1                1.5               0.2\n","4                5.0               3.6                1.4               0.2\n","     Component 1  Component 2\n","0      -2.264703     0.480027\n","1      -2.080961    -0.674134\n","2      -2.364229    -0.341908\n","3      -2.299384    -0.597395\n","4      -2.389842     0.646835\n","..           ...          ...\n","145     1.870503     0.386966\n","146     1.564580    -0.896687\n","147     1.521170     0.269069\n","148     1.372788     1.011254\n","149     0.960656    -0.024332\n","\n","[150 rows x 2 columns]\n","Datos transformados almacenados con éxito.\n"]}]}]}